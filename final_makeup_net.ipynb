{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [08/Sep/2020 12:40:31] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [08/Sep/2020 12:40:31] \"\u001b[33mGET /style.css HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [08/Sep/2020 12:40:31] \"\u001b[33mGET /display/ HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [08/Sep/2020 12:40:31] \"\u001b[37mGET /video_feed3?filename3= HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [08/Sep/2020 12:41:05] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [08/Sep/2020 12:41:05] \"\u001b[33mGET /style.css HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [08/Sep/2020 12:41:08] \"\u001b[37mGET /video_feed3?filename3=36ED8CED-87F0-443C-9743-1D0972362DCE.jpeg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [08/Sep/2020 12:41:09] \"\u001b[35m\u001b[1mGET /video_feed4 HTTP/1.1\u001b[0m\" 500 -\n",
      "Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\werkzeug\\serving.py\", line 323, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\werkzeug\\serving.py\", line 314, in execute\n",
      "    for data in application_iter:\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\werkzeug\\wsgi.py\", line 506, in __next__\n",
      "    return self._next()\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\werkzeug\\wrappers\\base_response.py\", line 45, in _iter_encoded\n",
      "    for item in iterable:\n",
      "  File \"<ipython-input-2-39dd39210bf1>\", line 116, in final\n",
      "    \n",
      "  File \"C:\\Users\\jkpar\\projects\\torch\\makeup\\eyecolor_convert.py\", line 205, in eyecolor_make\n",
      "    gen_image1 = model.predict(temp1)\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 957, in predict\n",
      "    return func.predict(\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 708, in predict\n",
      "    return predict_loop(\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 189, in model_iteration\n",
      "    f = _make_execution_function(model, mode)\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 557, in _make_execution_function\n",
      "    return model._make_execution_function(mode)\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2056, in _make_execution_function\n",
      "    self._make_predict_function()\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2041, in _make_predict_function\n",
      "    self.predict_function = K.function(\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3834, in function\n",
      "    return GraphExecutionFunction(inputs, outputs, updates=updates, **kwargs)\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3486, in __init__\n",
      "    with ops.control_dependencies([self.outputs[0]]):\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 5173, in control_dependencies\n",
      "    return get_default_graph().control_dependencies(control_inputs)\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 4591, in control_dependencies\n",
      "    c = self.as_graph_element(c)\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3512, in as_graph_element\n",
      "    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
      "  File \"C:\\Users\\jkpar\\.conda\\envs\\pytorch\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3591, in _as_graph_element_locked\n",
      "    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\n",
      "ValueError: Tensor Tensor(\"activation_8/Tanh:0\", shape=(None, 256, 256, 3), dtype=float32) is not an element of this graph.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import full_makeup\n",
    "import align_faces\n",
    "import dlib\n",
    "import os\n",
    "import eyecolor_convert\n",
    "from flask import Flask, flash, Response, request, redirect, url_for, render_template\n",
    "\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "\n",
    "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg', 'gif'])\n",
    "\n",
    "app = Flask(__name__)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "UPLOAD_FOLDER = 'static/uploads/'\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = \"secret key\"\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
    "\n",
    "\n",
    "\n",
    "#for cctv camera use rtsp://username:password@ip_address:554/user=username_password='password'_channel=channel_number_stream=0.sdp' instead of camera\n",
    "def gen_frames0():  # generate frame by frame from camera\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        success, frame = camera.read()  # read the camera frame\n",
    "        frame = cv2.resize(frame,(int(256),int(256)))\n",
    "\n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame = buffer.tobytes()\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')  # concat frame one by one and show result\n",
    "def gen_frames1(your_image):  # generate frame by frame from camera\n",
    "    # Capture frame-by-frame\n",
    "    frame = cv2.imread(your_image)  # read the camera frame\n",
    "    frame = cv2.resize(frame,(int(256),int(256)))\n",
    "    ret, buffer = cv2.imencode('.jpg', frame)\n",
    "    frame = buffer.tobytes()\n",
    "    yield (b'--frame\\r\\n'\n",
    "           b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')  # concat frame one by one and show result\n",
    "\n",
    "\n",
    "def gen_frames2(your_image = None, skin_image = None, lip_image=None,eye_image=None):  # generate frame by frame from camera\n",
    "    a=0\n",
    "    #frame = eyecolor_convert.eyecolor_make(your_image,[255,0,0])\n",
    "    frame = cv2.imread(your_image)\n",
    "    frame = cv2.resize(frame,(int(256),int(256)))\n",
    "    #frame = eyecolor_convert.eyecolor_make(frame,[255,0,0])\n",
    "    temp = frame[:,:,::-1].copy()\n",
    "    dets = detector(temp, 1)\n",
    "    if len(dets) != 0:\n",
    "        temp_face = align_faces.align_faces(temp)\n",
    "        src_img = temp_face[0]\n",
    "        faces1 = detector(src_img,1)\n",
    "        if len(faces1) !=0:\n",
    "            frame, final_output_no, makeup_frame =full_makeup.full_makeup(frame ,skin_image, lip_image, eye_image)\n",
    "            cv2.imwrite('test2.jpg',makeup_frame)\n",
    "            a=1\n",
    "            return makeup_frame\n",
    "        else:\n",
    "            if a == 0:\n",
    "                return frame\n",
    "            else:\n",
    "                return makeup_frame\n",
    "    else:\n",
    "        if a == 0:\n",
    "                return frame\n",
    "        else:\n",
    "             return makeup_frame\n",
    "                    \n",
    "def gen_frames3(your_image):  # generate frame by frame from camera\n",
    "    a=0\n",
    "    # Capture frame-by-frame\n",
    "    frame = cv2.imread(your_image)\n",
    "    frame = cv2.resize(frame,(int(256),int(256)))\n",
    "    temp = frame[:,:,::-1].copy()\n",
    "    dets = detector(temp, 1)\n",
    "    if len(dets) != 0:\n",
    "        temp_face = align_faces.align_faces(temp)\n",
    "        src_img = temp_face[0]\n",
    "        faces1 = detector(src_img,1)\n",
    "        if len(faces1) !=0:\n",
    "            src_img = src_img[:,:,::-1].copy()\n",
    "            ret, buffer = cv2.imencode('.jpg', src_img)\n",
    "            makeup_frame = buffer.tobytes()\n",
    "            a=1\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + makeup_frame + b'\\r\\n')  # concat frame one by one and show result\n",
    "        else:\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "            if a == 0:\n",
    "                yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')  # concat frame one by one and show result\n",
    "            else:\n",
    "                yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + makeup_frame + b'\\r\\n')  # concat frame one by one and show result\n",
    "    else:\n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame = buffer.tobytes()\n",
    "        if a == 0:\n",
    "            yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')  # concat frame one by one and show result\n",
    "        else:\n",
    "            yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + makeup_frame + b'\\r\\n')  # concat frame one by one and show result\n",
    "\n",
    "\n",
    "\n",
    "def final(you,skin,lip,eye):\n",
    "    global eyes \n",
    "    eyes = eyecolor_convert.eyecolor_make(you,[255,0,0])\n",
    "    #frame =gen_frames2(you,skin,lip,eye)\n",
    "    ret, buffer = cv2.imencode('.jpg',eyes)\n",
    "    frame = buffer.tobytes()\n",
    "    yield (b'--frame\\r\\n'\n",
    "        b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "@app.route('/')\n",
    "def upload_form():\n",
    "    return render_template('final.html')\n",
    "\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def upload_image():\n",
    "    if 'file' not in request.files or 'file1' not in request.files or 'file2' not in request.files:\n",
    "        flash('No file part')\n",
    "        return redirect(request.url)\n",
    "    file = request.files['file']\n",
    "    file1 = request.files['file1']\n",
    "    file2 = request.files['file2']\n",
    "    file3 = request.files['file3']\n",
    "    if file.filename == '' or file1.filename =='' or file2.filename ==''or file3.filename =='':\n",
    "        flash('No image selected for uploading')\n",
    "        return redirect(request.url)\n",
    "    if file and allowed_file(file.filename) and file1 and allowed_file(file1.filename) and file2 and allowed_file(file2.filename) and file3 and allowed_file(file3.filename):\n",
    "        global filename\n",
    "        filename = secure_filename(file.filename)\n",
    "        global filename1\n",
    "        filename1 = secure_filename(file1.filename)\n",
    "        global filename2\n",
    "        filename2 = secure_filename(file2.filename)\n",
    "        global filename3\n",
    "        filename3 = secure_filename(file3.filename)\n",
    "        global RR\n",
    "        global GG\n",
    "        global BB\n",
    "        RR = request.form['R']\n",
    "        GG= request.form['G']\n",
    "        BB= request.form['B']\n",
    "        \n",
    "        file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "        file1.save(os.path.join(app.config['UPLOAD_FOLDER'], filename1))\n",
    "        file2.save(os.path.join(app.config['UPLOAD_FOLDER'], filename2))\n",
    "        file3.save(os.path.join(app.config['UPLOAD_FOLDER'], filename3))\n",
    "        #print('upload_image filename: ' + filename)\n",
    "        flash('Image successfully uploaded and displayed')\n",
    "        return render_template('final.html', filename=filename, filename1=filename1, filename2=filename2, filename3=filename3)\n",
    "\n",
    "@app.route('/display/<filename3>')\n",
    "def video_feed0(filename3):\n",
    "    \"\"\"Video streaming route. Put this in the src attribute of an img tag.\"\"\"\n",
    "    return redirect(url_for('static', filename='uploads/' + filename3), code=301)\n",
    "\n",
    "@app.route('/display/<filename>')\n",
    "def display_image(filename):\n",
    "    #print('display_image filename: ' + filename0)\n",
    "    return redirect(url_for('static', filename='uploads/' + filename), code=301)\n",
    "\n",
    "@app.route('/display/<filename1>')\n",
    "def display_image1(filename1):\n",
    "    #print('display_image filename: ' + filename0)\n",
    "    return redirect(url_for('static', filename='uploads/' + filename1), code=301)\n",
    "\n",
    "@app.route('/display/<filename2>')\n",
    "def display_image2(filename2):\n",
    "    #print('display_image filename: ' + filename0)\n",
    "    return redirect(url_for('static', filename='uploads/' + filename2), code=301)\n",
    "\n",
    "\n",
    "@app.route('/video_feed3') #align\n",
    "def video_feed3():\n",
    "    \"\"\"Video streaming route. Put this in the src attribute of an img tag.\"\"\"\n",
    "    return Response(gen_frames3('static/uploads/'+filename3),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/video_feed4')\n",
    "def video_feed4():\n",
    "    if str(filename) != \"NONE.png\":\n",
    "        skin_image = 'static/uploads/'+str(filename)\n",
    "    else:\n",
    "        skin_image =None\n",
    "        \n",
    "    if str(filename1) != \"NONE.png\":\n",
    "        lip_image = 'static/uploads/'+str(filename1)\n",
    "    else:\n",
    "        lip_image =None\n",
    "        \n",
    "    if str(filename2) != \"NONE.png\":\n",
    "        eye_image = 'static/uploads/'+str(filename2)\n",
    "    else:\n",
    "        eye_image =None\n",
    "    \n",
    "    \"\"\"Video streaming route. Put this in the src attribute of an img tag.\"\"\"\n",
    "    return Response(final('static/uploads/'+filename3,skin_image,lip_image,eye_image),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()#host=\"192.168.123.109\",port=8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
